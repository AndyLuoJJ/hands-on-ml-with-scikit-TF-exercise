{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Decision Tree\n",
    "\n",
    "This chapter briefly introduces the principles of Decision Tree and how to use it with sklearn. This notebook contains my solution to Ex.7 and Ex.8. Due to the limitation of computing power of my laptop, grid search is not performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Decision Tree on Satellite dataset\n",
    "\n",
    "Requirement: Create and fine-tune a Decision Tree on Satellite dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, the first step is to prepare the dataset. Check the available APIs to assist you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, target = make_moons(n_samples=10000, noise=0.4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have the proper dataset, use it to train a Decision Tree. Grid search is not performed due to computing power limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     DecisionTreeClassifier(),\n",
    "#     param_grid={\"max_leaf_nodes\": [], \"max_depth\": []}, \n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     scoring=\"precision\"\n",
    "# )\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# model = grid_search.best_estimator_\n",
    "\n",
    "model = DecisionTreeClassifier(max_leaf_nodes=17, max_depth=None)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally check the general performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "predictions = model.predict(X_train)\n",
    "print(\"---------- Training ----------\")\n",
    "print(\"Precision Score:\", precision_score(y_train, predictions))\n",
    "print(\"AUC:\", roc_auc_score(y_train, predictions))\n",
    "predictions = model.predict(X_test)\n",
    "print(\"---------- Testing ----------\")\n",
    "print(\"Precision Score:\", precision_score(y_test, predictions))\n",
    "print(\"AUC:\", roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Grow a \"forest\"\n",
    "\n",
    "Requirement: Grow a Random Forest with Decision Tree based on the dataset and model above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the dataset above, we seperate the dataset into 1000 different subsets. Then, using the hyperparameters above, create 1000 Decision Trees on each training subset. Predict each test instance with these 1000 Decision Trees, and keep the most frequently predicted result. In this way, you create a Random Forest on your own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "n_trees = 1000\n",
    "n_samples = 100\n",
    "rs = ShuffleSplit(n_splits=n_trees, test_size=len(X_train) - n_samples, random_state=42)\n",
    "mini_sets = []\n",
    "for train_index, val_index in rs.split(X_train):\n",
    "    X_train_fold, y_train_fold = X_train[train_index], y_train[train_index]\n",
    "    mini_sets.append((X_train_fold, y_train_fold))\n",
    "    \n",
    "model_collection = [DecisionTreeClassifier(max_leaf_nodes=17) for _ in range(n_trees)]\n",
    "for model, (X_train_fold, y_train_fold) in zip(model_collection, mini_sets):\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the performance of Random Forest is better than single Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to find the element that occurs most frequently in a list.\n",
    "def max_occurence(input_array):\n",
    "    categories = []\n",
    "    count_dict = {}\n",
    "    for item in input_array:\n",
    "        if str(item) not in categories:\n",
    "            categories.append(str(item))\n",
    "            count_dict[str(item)] = 1\n",
    "        else:\n",
    "            count_dict[str(item)] += 1\n",
    "\n",
    "    max_value = 0\n",
    "    max_key = \"\"\n",
    "    for key, value in count_dict.items():\n",
    "        if value > max_value:\n",
    "            max_value = value\n",
    "            max_key = key\n",
    "\n",
    "    return int(max_key)\n",
    "\n",
    "\n",
    "# Use voting to create a random forest.\n",
    "import numpy as np\n",
    "prediction_result = []\n",
    "for test_instance in X_test:\n",
    "    prediction_collection = []\n",
    "    for model in model_collection:\n",
    "        prediction_collection.append(model.predict(test_instance))\n",
    "        \n",
    "    prediction_result.append(max_occurence(prediction_collection))\n",
    "\n",
    "prediction_result = np.array(prediction_result)\n",
    "print(\"Final Precision Score:\", precision_score(y_test, prediction_result))\n",
    "print(\"Final AUC:\", roc_auc_score(y_test, prediction_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
