{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10: Introduction to Artificial Neural Network\n",
    "\n",
    "This chapter introduces how to build a MLP using TensorFlow, both with higher level APIs and lower level operators. For advance usage tutorials on TensorFlow, check out the official documentation or other tutorials.\n",
    "\n",
    "> This jupyter notebook contains my own solution to the coding exercises of the book. For answers to the questions, plase refer to the markdown file under the same folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP on MNIST\n",
    "Requirement: Train a deep MLP on MNIST dataset, and try to get accuracy higher than 98%. Also, try to add some additional functions, such as saving checkpoint, resuming training, adding summary and plotting learning curve, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete code is shown below. It is similar to the code of proceeding moon dataset, but the structure of MLP is modified to conform to the requirement of MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# prepare for dataset\n",
    "dataset = np.load(\"/Users/Antinomy/.keras/datasets/mnist.npz\")\n",
    "X_train, y_train, X_test, y_test = dataset[\"x_train\"], dataset[\"y_train\"], dataset[\"x_test\"], dataset[\"y_test\"]\n",
    "X_train = np.reshape(X_train, (-1, 28*28))\n",
    "X_test = np.reshape(X_test, (-1, 28*28))\n",
    "\n",
    "# set up hyperparameters\n",
    "batch_size = 64\n",
    "num_epochs = 3000\n",
    "learning_rate = 0.001\n",
    "num_hidden_1 = 500\n",
    "num_hidden_2 = 300\n",
    "\n",
    "num_train_samples, num_features = X_train.shape[0], X_train.shape[1]\n",
    "num_batches = int(np.ceil(num_train_samples / batch_size))\n",
    "current_epoch = -1\n",
    "random_indexes = np.arange(num_train_samples)\n",
    "np.random.shuffle(random_indexes)\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"/Users/Antinomy/Desktop/tf_logs\"\n",
    "logdir = \"{}/run-{}\".format(root_logdir, now)\n",
    "\n",
    "# define computation graph\n",
    "# encapsulation of tensorflow API\n",
    "def fully_connected_layer(X, num_neurons, activation=\"sigmoid\"):\n",
    "    with tf.name_scope(\"fully_connected_layer\"):\n",
    "        layer_output = fully_connected(X, num_neurons, scope=\"\")\n",
    "        return layer_output\n",
    "\n",
    "input_tensor = tf.placeholder(tf.float32, shape=(None, num_features), name=\"input\")\n",
    "label = tf.placeholder(tf.int32, shape=(None,), name=\"label\")\n",
    "with tf.name_scope(\"MLP\") as scope:\n",
    "    hidden_1 = fully_connected(input_tensor, num_hidden_1, scope=\"hidden_1\")\n",
    "    hidden_2 = fully_connected(hidden_1, num_hidden_2, scope=\"hidden_2\")\n",
    "    logits = fully_connected(hidden_2, 10, scope=\"outputs\", activation_fn=None)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "loss_summary = tf.summary.scalar(\"crossentropy\", loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    if os.path.exists(\"/Users/Antinomy/Desktop/tmp/checkpoint\"):\n",
    "        saver.restore(sess, \"/Users/Antinomy/Desktop/tmp/my_model.ckpt\")\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        for j in range(num_batches):\n",
    "            if i != current_epoch:\n",
    "                random_indexes = np.arange(num_train_samples)\n",
    "                np.random.shuffle(random_indexes)\n",
    "                current_epoch += 1\n",
    "\n",
    "            selected_index = random_indexes[j*batch_size:(j+1)*batch_size]\n",
    "            X_train_batch, y_train_batch = X_train[selected_index], y_train[selected_index]\n",
    "            if j % 10 == 0:\n",
    "                summary_str = loss_summary.eval(feed_dict={input_tensor: X_train_batch, label: y_train_batch})\n",
    "                step = i*num_batches + j\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "\n",
    "            sess.run(training_op, feed_dict={input_tensor: X_train_batch, label: y_train_batch})\n",
    "\n",
    "        print(\"---------- Epoch %d ----------\" % (i))\n",
    "        print(\"Loss:\", loss.eval(feed_dict={input_tensor: X_train_batch, label: y_train_batch}))\n",
    "        save_path = saver.save(sess, \"/Users/Antinomy/Desktop/tmp/my_model.ckpt\")\n",
    "\n",
    "    saver.save(sess, \"/Users/Antinomy/Desktop/tmp/my_final_model.ckpt\")\n",
    "    file_writer.close()\n",
    "\n",
    "    # check the accuracy of trained model on train and test set\n",
    "    predictions = np.argmax(logits.eval(feed_dict={input_tensor: X_test, label: y_test}), axis=1)\n",
    "    print(\"========== Model Performance ==========\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "    print(\"AUC:\", roc_auc_score(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
