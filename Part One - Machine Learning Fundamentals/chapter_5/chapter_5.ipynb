{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 Support Vector Machine\n",
    "\n",
    "This chapter introduces the basic idea of Support Vector Machine(SVM). This notebook contains my own solutions to the exercises of the book, which includes Ex.8, Ex.9 and Ex.10.\n",
    "\n",
    "I've tested my code on my MBP. However, it will be a liitle bit slow to run grid search on my machine. Therefore, I directly set the hyperparameters of the model and train it with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9: SVM on MNIST\n",
    "\n",
    "Requirement: Train a SVM on MNIST dataset. Since SVM is a two-class classifier, you need to use one-versus-rest classifier to do multiclass classification. Besides, you might need validation set to speed up the process of tuning hyperparameters. Try and see the precision score of your final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as other machine learning algorithms, we need to prepare the dataset. Again we use the ```mnist-original.mat``` file in Chapter 3 to do SVM classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mnist = sio.loadmat(\"./mnist/mnist-original.mat\")\n",
    "data, target = np.transpose(mnist[\"data\"]), np.transpose(mnist[\"label\"])\n",
    "X_train, y_train, X_test, y_test = data[:60000], target[:60000], data[60000:], target[60000:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a OneVsRestClassifier to do multiclass classification. (Tuning of hyperparameters is omitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "\n",
    "split_folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in split_folds.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    ovr_clf = OneVsRestClassifier(SVC(kernel=\"rbf\", C=1, gamma=\"scale\"))\n",
    "    ovr_clf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = ovr_clf.predict(X_val_fold)\n",
    "    print(\"Validation Precision Score:\", precision_score(y_val_fold, y_pred))\n",
    "    print(\"Validation AUC:\", roc_auc_score(y_val_fold, y_pred))\n",
    "    \n",
    "final_model = OneVsRestClassifier(SVC(kernel=\"rbf\", C=1, gamma=\"scale\"))\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the precision score and AUC of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)\n",
    "predictions = final_model.predict(X_test)\n",
    "print(\"Test Precision score:\", precision_score(y_test, predictions))\n",
    "print(\"Test AUC:\", roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10: SVM on California housing dataset\n",
    "\n",
    "Requirement: Create a SVM regressor on California housing dataset. Try and see the precision score of your final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load California housing dataset with sklearn and preprocess it. If fetching data with sklearn, the dataset is well processed and can be used directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = california_housing.fetch_california_housing()\n",
    "data, target = housing[\"data\"], housing[\"target\"]\n",
    "X_train, X_test = data[:20000], data[20000:]\n",
    "y_train, y_test = target[:20000], target[20000:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create a SVM regressor to do regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "\n",
    "split_folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in split_folds.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    ovr_clf = SVR(kernel=\"rbf\", C=1, gamma=\"scale\")\n",
    "    ovr_clf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = ovr_clf.predict(X_val_fold)\n",
    "    print(\"Validation Precision Score:\", precision_score(y_val_fold, y_pred))\n",
    "    print(\"Validation AUC:\", roc_auc_score(y_val_fold, y_pred))\n",
    "    \n",
    "final_model = SVR(kernel=\"rbf\", C=1, gamma=\"scale\")\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally check the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform(X_test)\n",
    "predictions = final_model.predict(X_test)\n",
    "print(\"Test Precision Score:\", precision_score(y_test, predictions))\n",
    "print(\"Test AUC:\", roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a script for exporting the housing dataset to csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"dataset.csv\", 'w') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    header = [\"label\"]\n",
    "\n",
    "    for item in housing[\"feature_names\"]:\n",
    "        header.append(item)\n",
    "\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        content = []\n",
    "        content.append(target[i])\n",
    "        for item in data[i]:\n",
    "            content.append(item)\n",
    "\n",
    "        csv_writer.writerow(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
